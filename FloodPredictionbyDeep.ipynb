{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":73278,"databundleVersionId":8121328,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import Necessary Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import r2_score\nimport time\n\n# Load Datasets\nstart_time = time.time()\ntrain_df = pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv')\ntest_df = pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv')\nprint(f\"Data loading time: {time.time() - start_time} seconds\")\n\n# Prepare Data\nstart_time = time.time()\nX = train_df.drop(columns=['id', 'FloodProbability'])\ny = train_df['FloodProbability']\n\n# Impute missing values\nimputer = SimpleImputer(strategy='mean')\nX_imputed = imputer.fit_transform(X)\n\n# Standardize the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_imputed)\n\n# Split the data into training and validation sets\nX_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\nprint(f\"Data preparation time: {time.time() - start_time} seconds\")\n\n# Define and Train Models\nstart_time = time.time()\n\n# Initialize models\nmodels = {\n    'Linear Regression': LinearRegression(),\n    'Random Forest': RandomForestRegressor(random_state=42),\n    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n}\n\n# Train each model and evaluate its performance\nbest_model = None\nbest_score = -np.inf\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_valid)\n    score = r2_score(y_valid, y_pred)\n    print(f'{name} R2 Score: {score}')\n    \n    if score > best_score:\n        best_score = score\n        best_model = model\n\nprint(f\"Best Model: {best_model} with R2 Score: {best_score}\")\nprint(f\"Model training and evaluation time: {time.time() - start_time} seconds\")\n\n# Make Predictions and Prepare Submission\nstart_time = time.time()\nX_test = test_df.drop(columns=['id'])\nX_test_imputed = imputer.transform(X_test)\nX_test_scaled = scaler.transform(X_test_imputed)\ntest_predictions = best_model.predict(X_test_scaled)\n\nsubmission_df = pd.DataFrame({\n    'id': test_df['id'],\n    'FloodProbability': test_predictions\n})\n\n# Save submission file to the current directory\nsubmission_file_path = 'best_submission.csv'\nsubmission_df.to_csv(submission_file_path, index=False)\nprint(f\"Prediction and submission time: {time.time() - start_time} seconds\")\n\n# Download the Submission File (Kaggle specific code)\nfrom IPython.display import FileLink\nFileLink(submission_file_path)\n\n# Generate Visualizations\n# Feature Importance (if applicable)\nif hasattr(best_model, 'feature_importances_'):\n    feature_importances = best_model.feature_importances_\n    features = X.columns\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x=feature_importances, y=features)\n    plt.title('Feature Importance')\n    plt.show()\n\n# Predicted vs Actual\nplt.figure(figsize=(10, 6))\nplt.scatter(y_valid, y_pred, alpha=0.5)\nplt.xlabel('Actual Flood Probability')\nplt.ylabel('Predicted Flood Probability')\nplt.title('Predicted vs Actual Flood Probability')\nplt.plot([0, 1], [0, 1], 'r--')\nplt.show()\n\n# Residuals Plot\nresiduals = y_valid - y_pred\nplt.figure(figsize=(10, 6))\nsns.histplot(residuals, kde=True)\nplt.title('Residuals Distribution')\nplt.xlabel('Residuals')\nplt.ylabel('Frequency')\nplt.show()\n\n# Distribution of Predictions\nplt.figure(figsize=(10, 6))\nsns.histplot(test_predictions, kde=True)\nplt.title('Distribution of Test Predictions')\nplt.xlabel('Predicted Flood Probability')\nplt.ylabel('Frequency')\nplt.show()\n\n# Correlation Heatmap\ncorr_matrix = train_df.drop(columns=['id']).corr()\nplt.figure(figsize=(15, 10))\nsns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm')\nplt.title('Correlation Matrix')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-24T22:49:52.447287Z","iopub.execute_input":"2024-05-24T22:49:52.447734Z","iopub.status.idle":"2024-05-24T23:15:25.046275Z","shell.execute_reply.started":"2024-05-24T22:49:52.447704Z","shell.execute_reply":"2024-05-24T23:15:25.044718Z"},"trusted":true},"execution_count":null,"outputs":[]}]}